{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letter Recognition Using SVM\n",
    "\n",
    "Let's now tackle a slightly more complex problem - letter recognition. We'll first explore the dataset a bit, prepare it (scale etc.) and then experiment with linear and non-linear SVMs with various hyperparameters.\n",
    "\n",
    "\n",
    "## Data Understanding \n",
    "\n",
    "Let's first understand the shape, attributes etc. of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# dataset\n",
    "lettersdf = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions:  (42000, 785) \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# about the dataset\n",
    "\n",
    "# dimensions\n",
    "print(\"Dimensions: \", lettersdf.shape, \"\\n\")\n",
    "\n",
    "# data types\n",
    "print(lettersdf.info())\n",
    "\n",
    "# head\n",
    "lettersdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       0.0\n",
       "pixel0      0.0\n",
       "pixel1      0.0\n",
       "pixel2      0.0\n",
       "pixel3      0.0\n",
       "pixel4      0.0\n",
       "pixel5      0.0\n",
       "pixel6      0.0\n",
       "pixel7      0.0\n",
       "pixel8      0.0\n",
       "pixel9      0.0\n",
       "pixel10     0.0\n",
       "pixel11     0.0\n",
       "pixel12     0.0\n",
       "pixel13     0.0\n",
       "pixel14     0.0\n",
       "pixel15     0.0\n",
       "pixel16     0.0\n",
       "pixel17     0.0\n",
       "pixel18     0.0\n",
       "pixel19     0.0\n",
       "pixel20     0.0\n",
       "pixel21     0.0\n",
       "pixel22     0.0\n",
       "pixel23     0.0\n",
       "pixel24     0.0\n",
       "pixel25     0.0\n",
       "pixel26     0.0\n",
       "pixel27     0.0\n",
       "pixel28     0.0\n",
       "           ... \n",
       "pixel754    0.0\n",
       "pixel755    0.0\n",
       "pixel756    0.0\n",
       "pixel757    0.0\n",
       "pixel758    0.0\n",
       "pixel759    0.0\n",
       "pixel760    0.0\n",
       "pixel761    0.0\n",
       "pixel762    0.0\n",
       "pixel763    0.0\n",
       "pixel764    0.0\n",
       "pixel765    0.0\n",
       "pixel766    0.0\n",
       "pixel767    0.0\n",
       "pixel768    0.0\n",
       "pixel769    0.0\n",
       "pixel770    0.0\n",
       "pixel771    0.0\n",
       "pixel772    0.0\n",
       "pixel773    0.0\n",
       "pixel774    0.0\n",
       "pixel775    0.0\n",
       "pixel776    0.0\n",
       "pixel777    0.0\n",
       "pixel778    0.0\n",
       "pixel779    0.0\n",
       "pixel780    0.0\n",
       "pixel781    0.0\n",
       "pixel782    0.0\n",
       "pixel783    0.0\n",
       "Length: 785, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "round(100*(lettersdf.isnull().sum()/len(lettersdf.index)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no null values\n",
    "# and no outliers exists in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "all features are in range of 0-1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the average values do not vary a lot (e.g. having a diff of an order of magnitude). Nevertheless, it is better to rescale them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into X and y\n",
    "X = lettersdf.drop(\"label\", axis = 1)\n",
    "y = lettersdf['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features\n",
    "X_scaled = scale(X)\n",
    "# takeing a small train data set .to reduce train time\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.8, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "Let's fist build two basic models - linear and non-linear with default hyperparameters, and compare the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model\n",
    "\n",
    "model_linear = SVC(kernel='linear')\n",
    "model_linear.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = model_linear.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.913125 \n",
      "\n",
      "[[3188    0   10    5   11   20   32    3   15    1]\n",
      " [   0 3677   14   11    5    7    4    8   30    4]\n",
      " [  36   29 3027   54   55   10   30   42   48   12]\n",
      " [  13   12  104 3051    9  181    5   21   54   25]\n",
      " [   8   14   33    2 3057    4   25   31    6  110]\n",
      " [  30   23   29  136   44 2622   44   12   72   27]\n",
      " [  26   11   44    4   28   33 3113    0   18    0]\n",
      " [   7   24   36   19   59    9    2 3210    4  134]\n",
      " [  13   46   50  120   21  110   30   18 2843   21]\n",
      " [  19   17   21   22  172   20    4  161   26 2893]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix and accuracy\n",
    "\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "# cm\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model gives approx. 91% accuracy. Let's look at a sufficiently non-linear model with randomly chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-linear model\n",
    "# using rbf kernel, C=1, default value of gamma\n",
    "\n",
    "# model\n",
    "non_linear_model = SVC(kernel='rbf')\n",
    "\n",
    "# fit\n",
    "non_linear_model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = non_linear_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9396428571428571 \n",
      "\n",
      "[[3195    0   19    5    4   11   32    4   14    1]\n",
      " [   0 3689   23   12    8    3    7    6    8    4]\n",
      " [  15   15 3144   29   31    5   18   37   43    6]\n",
      " [   5    8   92 3191    5   73    6   31   43   21]\n",
      " [   3    7   57    1 3099    9   19   21    7   67]\n",
      " [  15   10   37   66   16 2776   53   15   32   19]\n",
      " [  19    5   46    1   12   31 3149    2   12    0]\n",
      " [   6   21   66   11   25    3    0 3285    3   84]\n",
      " [  14   24   40   63   14   62   22   19 2996   18]\n",
      " [  12   10   38   40   80    6    0   97   24 3048]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix and accuracy\n",
    "\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=y_test, y_pred=y_pred), \"\\n\")\n",
    "\n",
    "# cm\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-linear model gives approx. 93% accuracy. Thus, going forward, let's choose hyperparameters corresponding to non-linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search: Hyperparameter Tuning\n",
    "\n",
    "Let's now tune the model to find the optimal values of C and gamma corresponding to an RBF kernel. We'll use 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 42.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=101, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'gamma': [0.001, 0.0001, 1e-05], 'C': [10, 100, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 101)\n",
    "\n",
    "# specify range of hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "hyper_params = [ {'gamma': [ 1e-3, 1e-4,1e-5],\n",
    "                     'C': [ 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "# specify model\n",
    "model = SVC(kernel=\"rbf\")\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = model, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'accuracy', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.879429</td>\n",
       "      <td>0.407005</td>\n",
       "      <td>7.168695</td>\n",
       "      <td>0.122202</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.941071</td>\n",
       "      <td>0.938690</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939405</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999554</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999107</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.999345</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.298312</td>\n",
       "      <td>0.394807</td>\n",
       "      <td>6.592508</td>\n",
       "      <td>0.135461</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001}</td>\n",
       "      <td>0.933929</td>\n",
       "      <td>0.923214</td>\n",
       "      <td>0.931548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927262</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>4</td>\n",
       "      <td>0.957887</td>\n",
       "      <td>0.959970</td>\n",
       "      <td>0.959375</td>\n",
       "      <td>0.957738</td>\n",
       "      <td>0.959077</td>\n",
       "      <td>0.958810</td>\n",
       "      <td>0.000865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.661793</td>\n",
       "      <td>0.630059</td>\n",
       "      <td>10.480843</td>\n",
       "      <td>0.152750</td>\n",
       "      <td>10</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'C': 10, 'gamma': 1e-05}</td>\n",
       "      <td>0.911905</td>\n",
       "      <td>0.908929</td>\n",
       "      <td>0.908929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904405</td>\n",
       "      <td>0.006907</td>\n",
       "      <td>9</td>\n",
       "      <td>0.916071</td>\n",
       "      <td>0.916518</td>\n",
       "      <td>0.916220</td>\n",
       "      <td>0.921429</td>\n",
       "      <td>0.919196</td>\n",
       "      <td>0.917887</td>\n",
       "      <td>0.002107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.104610</td>\n",
       "      <td>1.242744</td>\n",
       "      <td>7.241091</td>\n",
       "      <td>0.190791</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>0.939881</td>\n",
       "      <td>0.936905</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939286</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.565184</td>\n",
       "      <td>0.144372</td>\n",
       "      <td>5.500521</td>\n",
       "      <td>0.119884</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001}</td>\n",
       "      <td>0.929762</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.925595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925595</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>6</td>\n",
       "      <td>0.994345</td>\n",
       "      <td>0.994494</td>\n",
       "      <td>0.994940</td>\n",
       "      <td>0.993006</td>\n",
       "      <td>0.994196</td>\n",
       "      <td>0.994196</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.828921</td>\n",
       "      <td>0.773564</td>\n",
       "      <td>6.523903</td>\n",
       "      <td>0.208848</td>\n",
       "      <td>100</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'C': 100, 'gamma': 1e-05}</td>\n",
       "      <td>0.930357</td>\n",
       "      <td>0.923214</td>\n",
       "      <td>0.929762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>5</td>\n",
       "      <td>0.954911</td>\n",
       "      <td>0.956399</td>\n",
       "      <td>0.955208</td>\n",
       "      <td>0.954911</td>\n",
       "      <td>0.956548</td>\n",
       "      <td>0.955595</td>\n",
       "      <td>0.000727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24.841032</td>\n",
       "      <td>0.346291</td>\n",
       "      <td>7.454482</td>\n",
       "      <td>0.213512</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.001}</td>\n",
       "      <td>0.939881</td>\n",
       "      <td>0.936905</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939286</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.109573</td>\n",
       "      <td>0.598039</td>\n",
       "      <td>5.623919</td>\n",
       "      <td>0.265567</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.0001}</td>\n",
       "      <td>0.921429</td>\n",
       "      <td>0.920238</td>\n",
       "      <td>0.924405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920357</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.956037</td>\n",
       "      <td>0.768097</td>\n",
       "      <td>5.703961</td>\n",
       "      <td>0.400762</td>\n",
       "      <td>1000</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'C': 1000, 'gamma': 1e-05}</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.922619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920119</td>\n",
       "      <td>0.003579</td>\n",
       "      <td>8</td>\n",
       "      <td>0.991220</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>0.991518</td>\n",
       "      <td>0.989137</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.990685</td>\n",
       "      <td>0.000829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0      24.879429      0.407005         7.168695        0.122202      10   \n",
       "1      19.298312      0.394807         6.592508        0.135461      10   \n",
       "2      40.661793      0.630059        10.480843        0.152750      10   \n",
       "3      26.104610      1.242744         7.241091        0.190791     100   \n",
       "4      14.565184      0.144372         5.500521        0.119884     100   \n",
       "5      18.828921      0.773564         6.523903        0.208848     100   \n",
       "6      24.841032      0.346291         7.454482        0.213512    1000   \n",
       "7      15.109573      0.598039         5.623919        0.265567    1000   \n",
       "8      14.956037      0.768097         5.703961        0.400762    1000   \n",
       "\n",
       "  param_gamma                        params  split0_test_score  \\\n",
       "0       0.001     {'C': 10, 'gamma': 0.001}           0.941071   \n",
       "1      0.0001    {'C': 10, 'gamma': 0.0001}           0.933929   \n",
       "2       1e-05     {'C': 10, 'gamma': 1e-05}           0.911905   \n",
       "3       0.001    {'C': 100, 'gamma': 0.001}           0.939881   \n",
       "4      0.0001   {'C': 100, 'gamma': 0.0001}           0.929762   \n",
       "5       1e-05    {'C': 100, 'gamma': 1e-05}           0.930357   \n",
       "6       0.001   {'C': 1000, 'gamma': 0.001}           0.939881   \n",
       "7      0.0001  {'C': 1000, 'gamma': 0.0001}           0.921429   \n",
       "8       1e-05   {'C': 1000, 'gamma': 1e-05}           0.925000   \n",
       "\n",
       "   split1_test_score  split2_test_score       ...         mean_test_score  \\\n",
       "0           0.938690           0.945833       ...                0.939405   \n",
       "1           0.923214           0.931548       ...                0.927262   \n",
       "2           0.908929           0.908929       ...                0.904405   \n",
       "3           0.936905           0.946429       ...                0.939286   \n",
       "4           0.923810           0.925595       ...                0.925595   \n",
       "5           0.923214           0.929762       ...                0.926667   \n",
       "6           0.936905           0.946429       ...                0.939286   \n",
       "7           0.920238           0.924405       ...                0.920357   \n",
       "8           0.916667           0.922619       ...                0.920119   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.003865                1            0.999405            0.999554   \n",
       "1        0.004678                4            0.957887            0.959970   \n",
       "2        0.006907                9            0.916071            0.916518   \n",
       "3        0.003783                2            1.000000            1.000000   \n",
       "4        0.003409                6            0.994345            0.994494   \n",
       "5        0.002877                5            0.954911            0.956399   \n",
       "6        0.003783                2            1.000000            1.000000   \n",
       "7        0.002877                7            1.000000            1.000000   \n",
       "8        0.003579                8            0.991220            0.990923   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.999405            0.999107            0.999256   \n",
       "1            0.959375            0.957738            0.959077   \n",
       "2            0.916220            0.921429            0.919196   \n",
       "3            1.000000            1.000000            1.000000   \n",
       "4            0.994940            0.993006            0.994196   \n",
       "5            0.955208            0.954911            0.956548   \n",
       "6            1.000000            1.000000            1.000000   \n",
       "7            1.000000            1.000000            1.000000   \n",
       "8            0.991518            0.989137            0.990625   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.999345         0.000152  \n",
       "1          0.958810         0.000865  \n",
       "2          0.917887         0.002107  \n",
       "3          1.000000         0.000000  \n",
       "4          0.994196         0.000645  \n",
       "5          0.955595         0.000727  \n",
       "6          1.000000         0.000000  \n",
       "7          1.000000         0.000000  \n",
       "8          0.990685         0.000829  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.879429</td>\n",
       "      <td>0.407005</td>\n",
       "      <td>7.168695</td>\n",
       "      <td>0.122202</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.941071</td>\n",
       "      <td>0.938690</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939405</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999554</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999107</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.999345</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.104610</td>\n",
       "      <td>1.242744</td>\n",
       "      <td>7.241091</td>\n",
       "      <td>0.190791</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>0.939881</td>\n",
       "      <td>0.936905</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939286</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24.841032</td>\n",
       "      <td>0.346291</td>\n",
       "      <td>7.454482</td>\n",
       "      <td>0.213512</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.001}</td>\n",
       "      <td>0.939881</td>\n",
       "      <td>0.936905</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939286</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_C  \\\n",
       "0      24.879429      0.407005         7.168695        0.122202       10   \n",
       "3      26.104610      1.242744         7.241091        0.190791      100   \n",
       "6      24.841032      0.346291         7.454482        0.213512     1000   \n",
       "\n",
       "  param_gamma                       params  split0_test_score  \\\n",
       "0       0.001    {'C': 10, 'gamma': 0.001}           0.941071   \n",
       "3       0.001   {'C': 100, 'gamma': 0.001}           0.939881   \n",
       "6       0.001  {'C': 1000, 'gamma': 0.001}           0.939881   \n",
       "\n",
       "   split1_test_score  split2_test_score       ...         mean_test_score  \\\n",
       "0           0.938690           0.945833       ...                0.939405   \n",
       "3           0.936905           0.946429       ...                0.939286   \n",
       "6           0.936905           0.946429       ...                0.939286   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.003865                1            0.999405            0.999554   \n",
       "3        0.003783                2            1.000000            1.000000   \n",
       "6        0.003783                2            1.000000            1.000000   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.999405            0.999107            0.999256   \n",
       "3            1.000000            1.000000            1.000000   \n",
       "6            1.000000            1.000000            1.000000   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.999345         0.000152  \n",
       "3          1.000000         0.000000  \n",
       "6          1.000000         0.000000  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7kAAAGHCAYAAAB1SJU0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzs3XmcXFWd///Xp5d0ks5CNtbsigJJ\nSAIdtoiASASURRgQFBBmEEeW+Q4zMAOjX+ELo/JDx3EcxRn0hwgjIqNfFUcdcWFxECUJIqtAAoR0\nAiEL2Tvp7Xz/uNXd1Z1O0km6urqrXs/Hox5dde+5t0534N316XPuuZFSQpIkSZKkUlBR7A5IkiRJ\nktRbLHIlSZIkSSXDIleSJEmSVDIsciVJkiRJJcMiV5IkSZJUMixyJUmSJEklwyJXkiRJklQyLHLV\nYxFxXkT8PiI2RcSbueeXR0QUu2+9ISJmRcTCiNic+zprB21HR8QPcj+LJRHx4S77P5zbvikifhgR\no/P2XRkRCyJia0TcWcBvSVIPmG2d2u5Jtm332IjYLyLuj4jlEZEiYnIhvldJHcy2Tm0Lkm09ONbP\nfEVikaseiYi/Bf4F+DywL7AP8JfAXGBQEbvWKyJiEPAj4D+AUcC3gB/ltnfnq0Aj2c/hI8DXImJa\n7lzTgH8HLszt3wzclnfscuAfgTt6/zuRtCvMtm3sSbZt91igFfhv4Oxe++YkbZfZto2CZJuf+fqx\nlJIPHzt8ACOBTcDZO2jzfuAPwHpgKXBj3r7JQAIuye17iyxo5wBPAWuBr+S1vxh4FPjn3L6XgWNy\n25cCbwIf7cl778L3OA9YBkTetteAk7tpW0sWdu/I23Y3cEvu+WeBe/L2vS3XfniX8/wjcGex/319\n+CjXh9m2TdvdzradHZu3rSr3M5tc7H9/Hz5K9WG2bdO2YNm2o2O79MHPfH38cCRXPXE0UEP2F7Pt\n2QRcBOxFFl6fiIgzu7Q5EjgQ+BDwJeCTwHuBacC5EXFcl7ZPAWOAe4B7ycL17cAFwFciYlhP3jsi\n1u7gcV2u2TTgqZRLopynctu7egfQklJ6MW/bH/PaTsu9BiCltJhcQHZzLknFY7Z1tifZtrNjJfUd\ns62zQmabn/n6KYtc9cRYYFVKqbltQ0T8Nhc2DRHx7pTSQymlp1NKrSmlp4DvAMd1Oc/NKaUtKaUH\nyALuOymlN1NKy4DfALPz2r6SUvpmSqkF+C4wAbgppbQ1d3wjWXCys/dOKe21g8ctuWbDgHVd+ruO\n7K94Xe2s7a6cS1LxmG2d7Um2mXtS/2G2dVbIbDP7+imLXPXEamBsRFS1bUgpHZNS2iu3ryIijoyI\nByNiZUSsI5vWMrbLeVbkPW/o5vWwHbQlpdRt+x6+985sBEZ02TYC2LAbbXflXJKKx2zbtbY72m/u\nSf2H2bZrbfck28y+fsoiVz3xGLAVOGMHbe4B7gcmpJRGAv8G9NXqfTt874jYuIPHP+SaPQscGtFp\nxcFDc9u7ehGoiogD87bNzGv7bO512/tPJZs2lD/VRVLxmW2d7Um27exYSX3HbOuskNnmZ75+yiJX\nO5VSWgv8H+C2iPiziBgWERWRLdVem2s2HFiTUtoSEUcAH97e+Qpgh++dUhq2g8dnc80eAlqAv4qI\nmoi4Mrf9113fLKW0Cfi/wE0RURsRc8l+kdyda/Jt4LSIODYiaoGbgP+bUtoAEBFVETEYqAQqI2Jw\n/l9bJfUNs62zPcm2HhxLLvdqci9rcq8l9TKzrbMCZ5uf+fopi1z1SErpVuBvgL8jWyVvBdmS6X8P\n/Ba4nCwANgCfBu7rw+7t8XunlBqBM8kWQlgL/DlwZm47EfEPEfGzLu85hOxn8R3gEymlZ3PnepZs\n6s23c/uH59q3+RTZtJ3ryBZjaMhtk9THzLZezbbtHpvTQDa1D+BPudeSCsBs65ts8zNf/xWp06Jk\nkiRJkiQNXI7kSpIkSZJKRsGK3Ii4IyLejIhntrM/IuLLEbEoIp6KiMPy9n00Il7KPT5aqD5KUm8w\n7ySVA7NO0kBRyJHcO4GTd7D/FLIbTB8IXAZ8DSAiRgM3kN1U+gjghogYVcB+StKeuhPzTlLpuxOz\nTtIAULAiN6X0CLBmB03OAO5Kmd8Be0XEfsD7gF+klNaklN4CfsGOA1WSisq8k1QOzDpJA0Uxr8k9\nAFia97o+t2172yVpoDLvJJUDs05Sv1DM+zR1d8PptIPt254g4jKy6TDU1tYeftBBB/XsnTevgbVL\neta210WnL9t+u9Ht0+222+55ctu22dzNeXbaBogd9LPb/d2dv5Dfa9f3UsmqqILh+/W4+cKFC1el\nlMYVsEc9Uby8k8pWgtZWSN09EqSW3NfttdnZI3fsroqK7HdmVOz8MXJ8j09r1kkqBz3NumIWufXA\nhLzX44Hlue3Hd9n+UHcnSCndDtwOUFdXlxYsWNCzd966ETavzhVm0fELh+jma9s+drBvR8fltm23\nCJRUSBFRrL9o5Ste3kn9TUrQvBWaNkNTQ+6xOe/r5m62NUDjpu2073pc7nVr8673rWowVA+B6qF5\nX4d22TYEBtVuu629bTftq4fCoKFQNQQqC/PRy6yTVA56mnXFLHLvB66MiHvJFiJYl1J6PSJ+Dnw2\nb0GCecD1vfrONcOyhyT1jeLlnbQrUtpBIbmdIrNxO0Vpp2O6FKC7MwK6vcJz8EgYvm9HIblN4dld\nAZq3r61grRoCFd5ZcQ+ZdZL6hYIVuRHxHbK/2o2NiHqyVfWqAVJK/wb8FDgVWARsBi7J7VsTETcD\n83OnuimltKNFDiSpqMw7FcW6ZbBxxQ5GPncwKtrdyGfb110VFdsvQIeO3cnI5xCoru2+KM0vWKsG\nOyOqHzDrJA0UBStyU0rn72R/Aq7Yzr47gDsK0S9J6m3mnQouJVi9CJb8tuOx7rWdHxeVuQKzmym0\nw/btUoDubJpu1wI097xykAVomTDrJA0UxZyuXHBNTU3U19ezZcuWYndFOzF48GDGjx9PdXV1sbsi\nDUjm3cDQ46xrbYU3n80VtI9mXzetzPbVjoNJx8DRV8CoyV2m3nYpTivNVJUWs25g8HOdiq2ki9z6\n+nqGDx/O5MmTCf/K3G+llFi9ejX19fVMmTKl2N2RBiTzrv/bYda1NMHrf+woaF97DLasy/aNGA9v\ne09W2E6aC2Pe7sipypZZ1//5uU49khKseRmW/wFm/Fmvn76ki9wtW7YYggNARDBmzBhWrlxZ7K5I\nA5Z51/91yrqmBqhf0DFSWz+/43rYMQfCIWdkBe2kY2CvicXtuNSPmHX9n5/r1K3WFljxbPZH3LY/\n5m5cke2bNBdG9Pz2kD1R0kUuYAgOEP47SXvO/4/6sdYWaNxENG7Mfql/7lhobQIC9pkOsy/MjdQe\nA8P2LnZvpX7NrOv//DcSzY3ZKO1ruXUkXvs9bM2boTTlOJh0NEw8Bobt0+tvX/JFbjGtXbuWe+65\nh8svv3y3jv/Sl77EZZddxtChQ3u5Z5LUu8y7LlqaoXFjx6OpIbcjIAFHfSL7y/XEI2HIqB2dSVI/\nYtZJ27F1I9Q/Dksey0Zp6+dDc+7a+bHvgGlndvwxtw9mKHlDuAJau3Ytt912224f/6UvfYnNm3fj\ndg69qLm5uajvL2lgKPu8a2mEzWtg7VJ483lY8TS89QpsWpWtcDxs3+xa2n1nwPB9YN7N8M6TLXCl\nAabss05qs3kN/Okn8PNPwu0nwC0T4e4Pwm++AFvXQ92fw7l3wzWL4Mr5cPqXYeZ5fXYJjkVuAV13\n3XUsXryYWbNmce211wLw+c9/njlz5nDooYdyww03ALBp0ybe//73M3PmTKZPn853v/tdvvzlL7N8\n+XJOOOEETjjhhG3OfdNNNzFnzhymT5/OZZddRrZqPyxatIj3vve9zJw5k8MOO4zFixcDcOuttzJj\nxgxmzpzJddddB8Dxxx/PggULAFi1ahWTJ08G4M477+Scc87htNNOY968eWzcuJETTzyRww47jBkz\nZvCjH/2ovR933XUXhx56KDNnzuTCCy9kw4YNTJkyhaamJgDWr1/P5MmT219LKk1ll3cf+TAbVrzK\nlEkTaKp/ElY8y/qlzzJ5xpE0tQLD98uurd3vUBh7YHatUc1wqKgsyM9fUt8ou6zzs53arKuHp/4T\n/utq+OpRcOsUuPfD8Pjt2b3M3/XXcMH34e+XwMcfgZM/B4ecDsPGFaW7ZTNd+f/8+FmeW76+V895\nyP4juOG0advdf8stt/DMM8/w5JNPAvDAAw/w0ksv8fjjj5NS4vTTT+eRRx5h5cqV7L///vzkJz8B\nYN26dYwcOZIvfvGLPPjgg4wdO3abc1955ZV8+tOfBuDCCy/kv/7rvzjttNP4yEc+wnXXXccHP/hB\ntmzZQmtrKz/72c/44Q9/yO9//3uGDh3KmjU7v//6Y489xlNPPcXo0aNpbm7mBz/4ASNGjGDVqlUc\nddRRnH766Tz33HN85jOf4dFHH2Xs2LGsWbOG4cOHc/zxx/OTn/yEM888k3vvvZezzz7bJeSlPmTe\n9XLenXYazz31Bz7zjzfx6E++y9jhNaxZvYrhLW9x/FGH8ZMHf8eZHzyLe394H2efcx7V+x68Oz9i\nSbvIrPOznQqk673ZX/strM3dm33QcJhwRLYi8qRjYP/DoHpwcfvbjbIpcvuDBx54gAceeIDZs2cD\nsHHjRl566SWOPfZYrrnmGv7+7/+eD3zgAxx77LE7PdeDDz7IrbfeyubNm1mzZg3Tpk3j+OOPZ9my\nZXzwgx8EsnuUAfzyl7/kkksuab/+Y/To0Ts9/0knndTeLqXEP/zDP/DII49QUVHBsmXLWLFiBb/+\n9a/5sz/7s/agbmt/6aWXcuutt3LmmWfyzW9+k69//eu7+JOSNNAN6Ly7/noeeeRhKgKWLatnxdMP\n8ev/+jl/dvJxjB1eA4OGMXryPjBoGJdedS23fv7znHnhX/LNu79t3kllZkBnnZ/t1Ka1BVY8k1fU\nPtZxb/ahY7MFoo78RFbU7jMdKvt/Cdn/e9hLdvRXub6SUuL666/n4x//+Db7Fi5cyE9/+lOuv/56\n5s2b1/6XvO5s2bKFyy+/nAULFjBhwgRuvPFGtmzZ0j6tpbv37W6Vu6qqKlpbW9vPma+2trb9+be/\n/W1WrlzJwoULqa6uZvLkye3v1915586dy6uvvsrDDz9MS0sL06dP3+73Iqn3mXe7mHdDh2YLZjRu\n5Nvf+hYrly5i4X/dkeXdkR9gSwwiDd6LGBawz7RO96id+6538eoVV5h3UhGYdX62025q3grLnuhY\n+Xjp49l1tAAjJ3bcm33iMdklNwNwtWyvyS2g4cOHs2HDhvbX73vf+7jjjjvYuHEjAMuWLePNN99k\n+fLlDB06lAsuuIBrrrmGJ554otvj27SF1tixY9m4cSPf+973ABgxYgTjx4/nhz/8IQBbt25l8+bN\nzJs3jzvuuKN9oYO2KS2TJ09m4cKFAO3n6M66devYe++9qa6u5sEHH2TJkiUAnHjiidx3332sXr26\n03kBLrroIs4//3wuueSSXf2xSRqABlTe/ed92VSs9cthwwrYvBpWvwQbXmfd2nXsve/+VO99IA8+\nt5Il9cthxHhOPOV07vve/2V17nzmnVSeBlTW+dlObbZugEW/gl/dDN88FT43Ab55MvzqpmzBxOln\nw1lfh79+Bq5+Gs66HQ6/GMa9Y0AWuFBGI7nFMGbMGObOncv06dM55ZRT+PznP8/zzz/P0UcfDcCw\nYcP4j//4DxYtWsS1115LRUUF1dXVfO1rXwPgsssu45RTTmG//fbjwQcfbD/vXnvtxcc+9jFmzJjB\n5MmTmTNnTvu+u+++m49//ON8+tOfprq6mv/8z//k5JNP5sknn6Suro5BgwZx6qmn8tnPfpZrrrmG\nc889l7vvvpv3vOc92/0+PvKRj3DaaadRV1fHrFmzOOiggwCYNm0an/zkJznuuOOorKxk9uzZ3Hnn\nne3HfOpTn+L888/v7R+rpH6oX+fdzTdxzZUf59yPXMTdd9zOe445PLtH7cYVQGt2LdGoqTColo/8\n5YQs7449ybyTtI1+nXV+tlObTauyKcdLHoMlj8IbT0NqyVb73+9QmHNpbqT2aKgdU+zeFkRsbxrE\nQFNXV5faVpNr8/zzz3PwwS4AUgzf+973+NGPfsTdd9/d42P891IhRMTClFJdsfvRm8y7nWhpyu5N\nm5uC3H6fPgIG1eYew7KvvbDa8a7mnf9WKgSzToVm1vVja5fmitpHs8J21QvZ9soaGF/XUdBOOCJb\n6X8A62nWOZKrXnfVVVfxs5/9jJ/+9KfF7oqkUpdSdo/axlxBu3UTtGzN9kVFVsgOGZUVtdVDoaJ3\nr9Ix7ySVA7OuH0kJVr3YsUDUkt/CuqXZvpoRMOFImPkhmDQX9p8NVTXF7W+RWOSq1/3rv/5rsbsg\nqVSllC2Y0V7UbsymHkM2DWvQsGzqVVtRW+Bricw7SeXArCuilmZY8XTeyse/g82rsn2147JR2qOv\nzFZA3me692PPsciVJPVfKUFTQ0dR27gJWpuzfRXV2UhtzbCsqK0aPGAXyJAkCYCmLbBsYW7l48dg\n6e+z338Ae02CA0/Kph5Pmgtj3ubvve2wyJUk9R+pFRo3dxS0jZuyxTIAKgdlU7EGDYOa2uxaI3+5\nS5IGsi3rs1v4LHk0m368bGF2GQ7AuIPh0A91XFM78oDi9nUAsciVJBVPaws0be5YJKpxE5BbELFq\ncO562txCUVWDitpVSZL22MaVHaO0Sx6FFc9kf+CNSth/FhxxWTZKO/EoGDq62L0dsCxyJUl9p7U5\nN0Kbu562qYH2orZ6CNSO7Vj5uLK6qF2VJGmPpARrX+u88vHql7J9VYNh/Bx497XZKO34OdnlN+oV\nFrkFtHbtWu655x4uv/zyXT721FNP5Z577mGvvfYqQM8kqXdtN+/abufTuCkrapsbcjsiWxhq2N6c\neu7F3HPPd9hrdGneq09S6fCznXYoJVj5QsfU4yWPwfr6bF/NyGx0dvZHspHa/WY5Q6mALHILaO3a\ntdx2223dBmFLSwuVldtf/ay/LtGeUiKlREUv34ZD0sDWnneXXdp55eOWrVneVVVnRe3wfXMrH9e2\n387np//9QJF73z3zTlJXfrZTJy3N8MYfc1OPc7f0aViT7Ru2T26BqP+VrXy89yGufNyH/K+5gK67\n7joWL17MrFmzuPbaa3nooYc44YQT+PCHP8yMGTMAOPPMMzn88MOZNm0at99+e/uxkydPZtWqVbz6\n6qscfPDBfOxjH2PatGnMmzePhoaGbd7rxz/+MUceeSSzZ8/mve99LytWrABg48aNXHLJJcyYMYND\nDz2U73//+wD893//N4cddhgzZ87kxBNPBODGG2/kC1/4Qvs5p0+fzquvvtreh8svv5zDDjuMpUuX\n8olPfIK6ujqmTZvGDTfc0H7M/PnzOeaYY5g5cyZHHHEEGzZs4Nhjj+XJJ59sbzN37lyeeuqpXvxJ\nSyqKlLJVIDet4rq/uYrFixcxa+YMrv3bv+ahX/2CE87+cz781zczY94FsO8Mzrz0Wg4//gNMO+wo\nbv/GN9pPY95JGij8bFfmWdfUAK/+Dzx8K9x1Jvx/k+Dr74EHPglvPgfvPAVO/wpc9QT87Qtw7rfg\nyMtg3xkWuH2sfEZyf3YdvPF0755z3xlwyi3b3X3LLbfwzDPPtIfAQw89xOOPP84zzzzDlClTALjj\njjsYPXo0DQ0NzJkzh7PPPpsxYzpP2XvppZf4zne+w9e//nXOPfdcvv/973PBBRd0avOud72L3/3u\nd0QE3/jGN7j11lv5p3/6J26++WZGjhzJ009n3/tbb73FypUr+djHPsYjjzzClClTWLNmzU6/1Rde\neIFvfvOb3HbbbQB85jOfYfTo0bS0tHDiiSfy1FNPcdBBB/GhD32I7373u8yZM4f169czZMgQLr30\nUu68806+9KUv8eKLL7J161YOPfTQnv+cJe2aQuXdyZ/Lphtv3dQxWpu7nc8t11/BM8+/yJO//x+o\nqeWh//k9j//haZ65+zvmnXknFYaf7QCzrqC2rIPXfp9bKOq3sOyJ3L3ZIxuZnXl+Nko78RgYsV+x\ne6s85VPk9hNHHHFEewgCfPnLX+YHP/gBAEuXLuWll17aJginTJnCrFmzADj88MN59dVXtzlvfX09\nH/rQh3j99ddpbGxsf49f/vKX3Hvvve3tRo0axY9//GPe/e53t7cZPXrnK7dNmjSJo446qv31fffd\nx+23305zczOvv/46zz33HBHBfvvtx5w5cwAYMWIEAOeccw4333wzn//857njjju4+OKLd/p+kvqD\nlK342NoCW9ZmHya3uZ1PbuXjrXtlC0UNG5ftjzDvzDupLJh1JZR1G9/Mitklv80K2zeeARJUVMH+\ns+GoT2S385lwpCsf93PlU+Tu4K9yfam2trb9+UMPPcQvf/lLHnvsMYYOHcrxxx/Pli1btjmmpqam\n/XllZWW3U1quuuoq/uZv/obTTz+dhx56iBtvvBHIrrOILveR7G4bQFVVFa2tre2v8/uS3+9XXnmF\nL3zhC8yfP59Ro0Zx8cUXs2XLlu2ed+jQoZx00kn86Ec/4r777mPBggXd/Wgk9ZbdzbvWVmjKX/l4\nc1bkQnZP2pphHSsfV9V0Prab//fNO/NOKig/27Uz63ZDSvDWq7kFonKF7ZrF2b6qITBhDhx/XW7l\n47rsd58GDK/JLaDhw4ezYcOG7e5ft24do0aNYujQofzpT3/id7/73W6/17p16zjggOwG0d/61rfa\nt8+bN4+vfOUr7a/feustjj76aB5++GFeeeUVgPYpLZMnT+aJJ54A4Iknnmjf39X69eupra1l5MiR\nrFixgp/97GcAHHTQQSxfvpz58+cDsGHDBpqbs6mMl156KX/1V3/FnDlzevTXRUl9oLUluwn9+uWw\n8kV44ylYvQg2vJHtGzoGRk2BfabDPofAXhOzv1x3LXAx78w7qTyYdQM461pbYcVz8PjX4Xt/Dl88\nBL48C374CXj+fhj7DjjpJrj0V3D9Uvjoj7Mid+pxFrgDUPmM5BbBmDFjmDt3LtOnT+eUU07h/e9/\nf6f9J598Mv/2b//GoYceyjvf+c5OU0Z21Y033sg555zDAQccwFFHHdUeYp/61Ke44oormD59OpWV\nldxwww2cddZZ3H777Zx11lm0tray995784tf/IKzzz6bu+66i1mzZjFnzhze8Y53dPteM2fOZPbs\n2UybNo2pU6cyd+5cAAYNGsR3v/tdrrrqKhoaGhgyZAi//OUvGTZsGIcffjgjRozgkksu2e3vUdIe\namnuuJa2se0etZDdzmdINtW4baS2Ytd+PZh35p1UDsy6AZR1LU3w+h87Vj1+7TFoeCvbN3y/3MrH\nx2SPcQe3r/iv0hAppWL3oVfU1dWlrlMlnn/+eQ4++OAi9Uj5li9fzvHHH8+f/vSn7S5R77+XCiEi\nFqaU6ordj97U47xraYat67N71DZuhOa2aWrRcS1tzbDs1j6u+thrdpZ3Zp0KoayzTkXR77KucTMs\nW9Ax9bh+fnbZDcDoqVkxOzFX1I6a3O1lNur/epp1juSq4O666y4++clP8sUvftF7sEl9qWkzrF0C\nUZEVtENG5UZqh2bb1OvMO0nloF9kXcNbnVc+Xv5kx8rH+0yH2RfkCtujs3u0q6xY5KrgLrroIi66\n6KJid0MqP4OGwdh3ZlOR/Yt1nzDvJJWDomTdhjfyVj5+DFY8S7bycXW28vHRV3SsfDxkr77tm/od\ni1xJKlUVFdmorSRJA8361+HV38ArD+dWPn45215dm1v5+PqsqD3gcH/XaRslX+Rub+lz9S+lcm24\nVEzmXf9n1kl7zqzr/3Yr6zavyRW1j2SPVS9m2wePhElzoe7Ps2tq9zs0uy+7tAMFLXIj4mTgX4BK\n4BsppVu67J8E3AGMA9YAF6SU6nP7WoCnc01fSymdvqvvP3jwYFavXs2YMWMMw34spcTq1asZPHhw\nsbsi7ZZiZx2YdwOBWaeBzqxTT/Q467asz6Ydv/JINlr7xjNAykZqJx0Dsy+EKe+GfWe4OKJ2WcGK\n3IioBL4KnATUA/Mj4v6U0nN5zb4A3JVS+lZEvAf4HHBhbl9DSmnWnvRh/Pjx1NfXs3Llyj05jfrA\n4MGDGT9+fLG7Ie2y/pB1YN4NFGadBiqzTrui26xraoClv+8YqV32BKQWqKyBCUfACZ/MitoDDnOk\nVnuskCO5RwCLUkovA0TEvcAZQH4YHgJcnXv+IPDD3uxAdXU1U6ZM6c1TSlJXRc86MO8kFZxZp13T\n3AhLHusoausfh5ZGiMrsOtp3XZ0VtROOyBZIlHpRIYvcA4Clea/rgSO7tPkjcDbZ1JcPAsMjYkxK\naTUwOCIWAM3ALSmlXg9KSeoFZp2kcmDWacdaW+D1P3YUta89lrtPbWRTjo+4DKYcB5OOhprhxe6t\nSlwhi9zuLpToehX6NcBXIuJi4BFgGVn4AUxMKS2PiKnAryPi6ZTS4k5vEHEZcBnAxIkTe7PvktRT\nBc86MO8kFZ1Zp85Sgjef7yhqX/0f2Lou2zfuoOw+tVPenS0aNXR0cfuqslPIIrcemJD3ejywPL9B\nSmk5cBZARAwDzk4prcvbR0rp5Yh4CJgNLO5y/O3A7QB1dXUuWSmpGAqedbn95p2kYjLryl1K2W18\n2ova38Cm3LXRoybDtDOykdrJ74Lh+xa1q1Ihi9z5wIERMYXsL3nnAR/ObxARY4E1KaVW4HqyFfmI\niFHA5pTS1lybucCtBeyrJO0us05SOTDrytG6+lxRm7u1z/r6bPvw/eBt78lGaicfC6MmFbefUhcF\nK3JTSs0RcSXwc7Kl5u9IKT0bETcBC1JK9wPHA5+LiEQ2reWK3OEHA/8eEa1ABdm1G89t8yaSVGRm\nnaRyYNaViY0r4dVHOkZr17ycbR8yGqYcC1OuzkZrx7wdvIWT+rEolRvT19XVpQULFhS7G5L6mYhY\nmFKqK3Y/epN5J6krs067pWEtLHm0o6h9M/e3h5oR2bW0U96dPfY+BCoqittXiZ5nXSGnK0uSJEnq\nLxo3ZasetxW1r/8RUitUDYGg/5+oAAAgAElEQVSJR8GMc7KR2v1mQqVlggYu/+uVJEmSSlHzVqif\nn3ev2gXQ2gQV1TB+Drz777KR2vF1UFVT7N5KvaYsi9znlq/n58++sc327i4tiG5WzO/arrsrEro9\nVw+vXdj2/Dvvwy71o0vLnl5S0V3/e/Ke3bfZ/e+pa8Oeft8qDcMHV3P6zP2L3Q1JkvqflmZY/gd4\n5eGsqF36e2jeAlEB+82Co6/IitqJR8Gg2mL3ViqYsixy//TGev7lVy8VuxuSdsOUsbUWuZIkAbS2\nwopnOkZql/wWGjdk+/aZDodfkrtX7TEwZK/i9lXqQ2VZ5J512HjOOmx8p23dLcDV3ZpcXTd1e1w3\n79n9uXr2nr15rt7sf3cNu/ajJ33Yk3509313e6BKRkWFw/SSpDKVEqx6qWOk9tXfQMNb2b4xb4dD\nz+m4rU/t2OL2VSqisixyu9PT6bPdHNnrfZEkSZIAeGtJx0jtK4/AxtwldyPGwztP7ShqRx5Q3H5K\n/YhFriRJktRfbHgDXvlNx2jt2iXZ9tpxHbf0mfJuGDXFRUik7bDIlSRJkopl85ps2nHbSO2qF7Pt\ng0dmI7RHXwlTjoVxB1nUSj1kkStJkiT1lS3r8+5V+zC88QyQoLo2WyBq9oXZSO2+M6Cisti9lQYk\ni1xJkiSpUJoaslv5tI3ULnsCUgtU1sCEI+CET2ZF7QGHQWV1sXsrlQSLXEmSJKm3NDfCsoUdU5CX\n/h5aGiEq4YDD4V1XZ0XthCOgekixeyuVJItcSZIkaXe1tsDrf+wYqX3tMWjaDEQ25fiIy2DKcTDp\naKgZXuzeSmXBIleSStSiNzfyjd+8TEVFUBlBZUVQEUFlBdts2972yorI20b7tsqKIGLb7d0d32l/\nbH9723nbn0dQ0U2biuj+tm+S1CdSgjef7yhql/wPbFmX7Rt3EMy+IBupnTQXho4ubl9LwIYtTTQ0\ntVA7qIoh1ZVUVJj/2jmLXEkqUW9tbuTXf3qT1pRoac0erYnseUq05r6mVOye7rqKoJuCuKMI7r54\nZrsFdf4xnbdnxXh379X1fNseT0e/2o/Z9o8F234PdNoW3fxRoK3toKoKBldVMri6gsHVlQyprmRw\ndSU1VRV+EJR6S0qw5uWOovbV38Cmldm+UZPhkDOykdrJ74Lh+xa1qwNVc0srS99q4OWVG3l55SZe\nXrWRxSs38fLKTazauLVT28HVFVnBO6iy42tNJUOqq6itqWTooI7nndoMqmLooMrco+O4odVVDK2p\npLqyokjfvQrBIleSStScyaN5/JPv3Wm7lDqK3/aCuK0Ibn9O+7a2NtnXHR+XuhbV+cdt8x65fmzT\nNv/4Lv3I2779vidaUrZ/2/PSqW1jc2vnvnTXh7afR6d+978/ImQFcFb8dhTAFdTkXrfta9s+uLoy\nty8rnIcM6nie7cudq7t9FtUqNevqc/eqzRW26+uz7cP3g7e9JxupnXwsjJpU3H4OICkl1mxq5JVV\nWfG6eFWuoF25kdfWbKappSMsR9cOYurYWt5z0DimjhtGbU0VDY3NbG5syT2a2bw1e76psZmGxhbW\nbGqgobGZTY0tNOTatO5C/lZXBkO7FMLdPq+pYmh17utO2tbWVFFTVeHsoyKwyJWkMpdNO85GJdX7\nUqciOVek7+CPCF2L5JbW7v9Y0FaUb2lqZWtz9qFuS1MLW5pbs69NbV9bOl43Z8/XNzTxZjfbtzS1\n7vb3OaiqolPB3DbCXNOlkM4fed5mX17hPLjT9s7Ftx8a1es2roRXH+kobNcszrYPGZ3do3bK1dlo\n7Zi3e6/andja3MKS1Zt5eWXHaOzLuYJ2XUNTe7tBlRVMGjOUt+89jHnT9mXq2FqmjhvG28bVstfQ\nQXvcj5QSW5tbs0J4azMNTbmvjS1saiuUc0VzfnG8aWszm5ta2Lw1279qYyObGzd3KrDzC/KdqQg6\nRo4HVTKkU0GcPxqdTcfORqCzQrrteXZc3mh0rq2/t7fPIleSpAKKCKoqY0D8wm37UNipSG7Onjc0\nZs+3dimgG/Labe20vaPd2oYmtq7fdvvW5t0vqmuqKjoXwlWVDB5UmTd63XnkuaZTAd15FLumS/G9\nzQi3RXXpaVgLSx7tGKl987lse82I7F61c/4iG63dexpUOI21q5QSb27YyuK26cV5hWz9W5s7jaDu\nM6KGqWOH8YFD92PquGFMHVfL28YO44BRQwpapEVE+//Po2v3vGjO19TS2jGi3NiSG1XuKJrbRpc7\ntcl93bS1hYamZjZsaebN9Vs7tW1oatmlftRUVWxTHNd2GVHuPGU7t72m66hz55HoQVUD/7/5gfA7\nV5Ik9YH8D4V9obU10djSuk3x22mEubGj0N7ZCPWWplYamlpYu7mx2+2NvVBUbzO9u5vt7dO7q9oK\n5s4j0jV5xffgbopvi+oCaNyUrXrcVtS+/kdIrVA1BCYeBTPOyUZq95sJlX48brO5sTlXwG5qv172\nldzzTY0dBdmQ6kqmjK3l0PEjOXP2AbxtXC1Txw5jyrhahtWU3s+zurKCkUMqGDmkd+9r3NqashHn\nXOHbVhBv2tq5YG7IK6Q35RfauRHotZubtmm7K1O3qyqio/jdpiDefnGcXRvd+bj8a6IHV/ddtpXe\nf3WSJGlAqKgIBldkBd5effB+ra15I9VdRqi3NOWNRDe30NDYud3Wbkao26aGr93cyOtdC/Dm1j0q\nqkcOqeaPN8zrxe++zDRvhfr5HUVt/QJobYKKahg/B979d9lI7fg6qKopdm+LqrU1sWxtQ6dCtm1U\n9vV1W9rbRcD+I4cwdVwt59RNYGqukJ06rpZ9Rwz2uvxeUFER1NZUUdvLfxjIn7qdP+LcNiW7o2Bu\n2eba5/xp3Gs2NbJ0TX7bFhpbep5zETC0etsp29+85Ihe/4OBRa4kSSoLFRXBkNz0vb7Q0prY2rxr\nI9QNTdmU8AG46HlxtTTD60/CKw/n7lX7O2jeAlEB+82Co6/IitqJR8Gg2mL3tijWNTR1KmLbFoB6\nZdWmTpcODB9cxdRxwzh66piskM1NMZ48prbPZnmod/XF1O1Oo8vt1zV3f+1z12ncgwqwsrVFriRJ\nUgFUVrSt1lrsnpS4N56BO06Gxg3Z632mw+GX5O5VewwM6Yt5Av1DU0srS9ds7jQa2/Z81cbG9naV\nFcHE0UOZOraWYw8cmxWyuYWfxg4b5HR59Vihpm7vKYtcSZIkDVxj3g6Hnputgjz5WKgdW+weFVRK\nidXtt+LJCtnFuUL2tdWbac67+HJM7SCmjqvlxIP2Ycq42vZCduLooSWxuJC0PRa5kiRJGriqB8MH\nvljsXvS6LU0dt+J5edWmvJWMN7J+S3N7u0GVFUweO5R37D2ck6ft2z69eOrY3rkVjzQQWeRKkiRJ\nRZBSYsX6rdk9Zbss/FT/VgOpm1vxnDZz/z69FY80EFnkSpIkSQW0aWszr+SPxuYK2ldWbWJz3q14\nhg7KbsUza8Iozpo9Pitkxw1j8tjSvBWPVCj+3yJJkiTtoZbWxPK1DXmFbMfCT2+s73wrngP2GsLU\nccOYM3l0dk/ZcR234nHRJ2nPWeRKkiRJPbRucxOLV3VcH9t2G55XVm/qdG/kEblb8RzzNm/FI/U1\ni1xJkiQpT1NLK6+13Yqny8js6k0dt+KparsVz7hajnvnuPbVi6eOq2VMrbfikYrFIleSJEllJ6XE\nqo2N7dfGvpy38NNra7q/Fc97D96n06jsxNFDqa70VjxSf2ORK0mSpJK1pamFV1dv6jQqu3jVJl7p\neiueqgqmjKnlnfsO55QZ+zJ1bNuteIYxcmh1Eb8DSbvKIleSJEkDWkqJ19dtyUZkV25kcd4KxsvW\ndr4Vz74jBjN1XC2nz9q/vZB927hh7L+Xt+KRSoVFriRJkgasF97YwJlffZSGps634pk6rpbZE0dx\n9mEdt+KZMraWWm/FI5W8gv5fHhEnA/8CVALfSCnd0mX/JOAOYBywBrggpVSf2/dR4FO5pv+YUvpW\nIfsqSbvLrJNUDvpr1u2/12DOO2ICU8cN4225hZ/2GVHjok9SGStYkRsRlcBXgZOAemB+RNyfUnou\nr9kXgLtSSt+KiPcAnwMujIjRwA1AHZCAhblj3ypUfyVpd5h1kspBf8664YOrueG0ab1xKkklopDL\nwR0BLEopvZxSagTuBc7o0uYQ4Fe55w/m7X8f8IuU0ppcAP4COLmAfZWk3WXWSSoHZp2kAaOQRe4B\nwNK81/W5bfn+CJyde/5BYHhEjOnhsUTEZRGxICIWrFy5stc6Lkm7oOBZB+adpKIz6yQNGIUscru7\nECJ1eX0NcFxE/AE4DlgGNPfwWFJKt6eU6lJKdePGjdvT/krS7ih41oF5J6nozDpJA0YhF56qBybk\nvR4PLM9vkFJaDpwFEBHDgLNTSusioh44vsuxDxWwr5K0u8w6SeXArJM0YBRyJHc+cGBETImIQcB5\nwP35DSJibES09eF6shX5AH4OzIuIURExCpiX2yZJ/Y1ZJ6kcmHWSBoyCFbkppWbgSrIQex64L6X0\nbETcFBGn55odD7wQES8C+wCfyR27BriZLFDnAzfltklSv2LWSSoHZp2kgSRS6vaSiAGnrq4uLViw\noNjdkNTPRMTClFJdsfvRm8w7SV2ZdZLKQU+zrpDTlSVJkiRJ6lMWuZIkSZKkkmGRK0mSJEkqGRa5\nkiRJkqSSYZErSZIkSSoZFrmSJEmSpJJhkStJkiRJKhkWuZIkSZKkkmGRK0mSJEkqGRa5kiRJkqSS\nYZErSZIkSSoZFrmSJEmSpJJhkStJkiRJKhkWuZIkSZKkkmGRK0mSJEkqGRa5kiRJkqSSYZErSZIk\nSSoZFrmSJEmSpJJhkStJkiRJKhkWuZIkSZKkkmGRK0mSJEkqGRa5kiRJkqSSYZErSZIkSSoZFrmS\nJEmSpJJhkStJkiRJKhkWuZIkSZKkkmGRK0mSJEkqGRa5kiRJkqSSYZErSZIkSSoZFrmSJEmSpJJh\nkStJkiRJKhkWuZIkSZKkklHQIjciTo6IFyJiUURc183+iRHxYET8ISKeiohTc9snR0RDRDyZe/xb\nIfspSXvCrJNUDsw6SQNFVaFOHBGVwFeBk4B6YH5E3J9Sei6v2aeA+1JKX4uIQ4CfApNz+xanlGYV\nqn+S1BvMOknlwKyTNJAUciT3CGBRSunllFIjcC9wRpc2CRiRez4SWF7A/khSIZh1ksqBWSdpwChk\nkXsAsDTvdX1uW74bgQsiop7sr31X5e2bkpvu8nBEHNvdG0TEZRGxICIWrFy5she7Lkk9VvCsA/NO\nUtGZdZIGjEIWudHNttTl9fnAnSml8cCpwN0RUQG8DkxMKc0G/ga4JyJGdDmWlNLtKaW6lFLduHHj\nern7ktQjBc86MO8kFZ1ZJ2nAKGSRWw9MyHs9nm2nrfwFcB9ASukxYDAwNqW0NaW0Ord9IbAYeEcB\n+ypJu8usk1QOzDpJA0Yhi9z5wIERMSUiBgHnAfd3afMacCJARBxMFoYrI2JcboEDImIqcCDwcgH7\nKkm7y6yTVA7MOkkDRsFWV04pNUfElcDPgUrgjpTSsxFxE7AgpXQ/8LfA1yPiarIpLxenlFJEvBu4\nKSKagRbgL1NKawrVV0naXWadpHJg1kkaSCKlrpdTDEx1dXVpwYIFxe6GpH4mIhamlOqK3Y/eZN5J\n6sqsk1QOepp1hZyuLEmSJElSn7LIlSRJkiSVDItcSZIkSVLJsMiVJEmSJJUMi1xJkiRJUsmwyJUk\nSZIklQyLXEmSJElSybDIlSRJkiSVDItcSZIkSVLJsMiVJEmSJJUMi1xJkiRJUsmwyJUkSZIklQyL\nXEmSJElSybDIlSRJkiSVjJ0WuRFxZUSM6ovOSFKxmHWSyoFZJ6kc9GQkd19gfkTcFxEnR0QUulOS\nVARmnaRyYNZJKnk7LXJTSp8CDgT+f+Bi4KWI+GxEvK3AfZOkPmPWSSoHZp2kctCja3JTSgl4I/do\nBkYB34uIWwvYN0nqU2adpHJg1kkqdVU7axARfwV8FFgFfAO4NqXUFBEVwEvA3xW2i5JUeGadpHJg\n1kkqBzstcoGxwFkppSX5G1NKrRHxgcJ0S5L6nFknqRyYdZJKXk+mK/8UWNP2IiKGR8SRACml5wvV\nMUnqY2adpHJg1kkqeT0pcr8GbMx7vSm3TZJKiVknqRyYdZJKXk+K3MgtUABk01no2TRnSRpIzDpJ\n5cCsk1TyelLkvhwRfxUR1bnH/wJeLnTHJKmPmXWSyoFZJ6nk9aTI/UvgGGAZUA8cCVxWyE5JUhGY\ndZLKgVknqeTtdHpKSulN4Lw+6IskFY1ZJ6kcmHWSykFP7pM7GPgLYBowuG17SunPC9gvSepTZp2k\ncmDWSSoHPZmufDewL/A+4GFgPLChkJ2SpCIw6ySVA7NOUsnrSZH79pTS/wY2pZS+BbwfmFHYbklS\nnzPrJJUDs05SyetJkduU+7o2IqYDI4HJBeuRJBWHWSepHJh1kkpeT+6LdntEjAI+BdwPDAP+d0F7\nJUl9z6yTVA7MOkklb4cjuRFRAaxPKb2VUnokpTQ1pbR3Sunfe3LyiDg5Il6IiEURcV03+ydGxIMR\n8YeIeCoiTs3bd33uuBci4n27/J1JUg+ZdZLKgVknqVzssMhNKbUCV+7OiSOiEvgqcApwCHB+RBzS\npdmngPtSSrPJlrO/LXfsIbnX04CTgdty55OkXmfWSSoHZp2kctGTa3J/ERHXRMSEiBjd9ujBcUcA\ni1JKL6eUGoF7gTO6tEnAiNzzkcDy3PMzgHtTSltTSq8Ai3Lnk6RCMesklQOzTlLJ68k1uW33Tbsi\nb1sCpu7kuAOApXmv64Eju7S5EXggIq4CaoH35h37uy7HHtCDvkrS7jLrJJUDs05SydtpkZtSmrKb\n547uTtfl9fnAnSmlf4qIo4G7cyv99eRYIuIy4DKAiRMn7mY3Jal/Zx2Yd5J6h1knqRzstMiNiIu6\n255Sumsnh9YDE/Jej6dj2kqbvyC7NoOU0mMRMRgY28NjSSndDtwOUFdX121YSlJP9Oesyx1n3kna\nY2adpHLQk2ty5+Q9jiWbinJ6D46bDxwYEVMiYhDZggP3d2nzGnAiQEQcDAwGVubanRcRNRExBTgQ\neLwH7ylJu8usk1QOzDpJJa8n05Wvyn8dESOBu3twXHNEXAn8HKgE7kgpPRsRNwELUkr3A38LfD0i\nriabtnJxSikBz0bEfcBzQDNwRUqpZRe/N0nqMbNOUjkw6ySVg8iyZxcOiKgGnkopHVyYLu2eurq6\ntGDBgmJ3Q1I/ExELU0p1u3Fcv8w6MO8kbcusk1QOepp1Pbkm98d0LA5QQXZvtPv2rHuS1L+YdZLK\ngVknqRz05BZCX8h73gwsSSnVF6g/klQsZp2kcmDWSSp5PSlyXwNeTyltAYiIIRExOaX0akF7Jkl9\ny6yTVA7MOkklryerK/8n0Jr3uiW3TZJKiVknqRyYdZJKXk+K3KqUUmPbi9zzQYXrkiQVhVknqRyY\ndZJKXk+K3JUR0X7/tIg4A1hVuC5JUlGYdZLKgVknqeT15JrcvwS+HRFfyb2uBy4qXJckqSjMOknl\nwKyTVPJ2WuSmlBYDR0XEMLL76m4ofLckqW+ZdZLKgVknqRzsdLpyRHw2IvZKKW1MKW2IiFER8Y99\n0TlJ6itmnaRyYNZJKgc9uSb3lJTS2rYXKaW3gFML1yVJKgqzTlI5MOsklbyeFLmVEVHT9iIihgA1\nO2gvSQORWSepHJh1kkpeTxae+g/gVxHxzdzrS4BvFa5LklQUZp2kcmDWSSp5PVl46taIeAp4LxDA\nfwOTCt0xSepLZp2kcmDWSSoHPZmuDPAG0AqcDZwIPF+wHklS8Zh1ksqBWSeppG13JDci3gGcB5wP\nrAa+S7bU/Al91DdJKjizTlI5MOsklZMdTVf+E/Ab4LSU0iKAiLi6T3olSX3HrJNUDsw6SWVjR9OV\nzyabzvJgRHw9Ik4ku3ZDkkqJWSepHJh1ksrGdovclNIPUkofAg4CHgKuBvaJiK9FxLw+6p8kFZRZ\nJ6kcmHWSyslOF55KKW1KKX07pfQBYDzwJHBdwXsmSX3IrJNUDsw6SeWgp6srA5BSWpNS+veU0nsK\n1SFJKjazTlI5MOsklapdKnIlSZIkSerPLHIlSZIkSSXDIleSJEmSVDIsciVJkiRJJcMiV5IkSZJU\nMixyJUmSJEklwyJXkiRJklQyLHIlSZIkSSXDIleSJEmSVDIsciVJkiRJJcMiV5IkSZJUMixyJUmS\nJEklo6BFbkScHBEvRMSiiLium/3/HBFP5h4vRsTavH0tefvuL2Q/JWlPmHWSyoFZJ2mgqCrUiSOi\nEvgqcBJQD8yPiPtTSs+1tUkpXZ3X/ipgdt4pGlJKswrVP0nqDWadpHJg1kkaSAo5knsEsCil9HJK\nqRG4FzhjB+3PB75TwP5IUiGYdZLKgVknacAoZJF7ALA073V9bts2ImISMAX4dd7mwRGxICJ+FxFn\nFq6bkrRHzDpJ5cCskzRgFGy6MhDdbEvbaXse8L2UUkvetokppeURMRX4dUQ8nVJa3OkNIi4DLgOY\nOHFib/RZknZVwbMOzDtJRWfWSRowCjmSWw9MyHs9Hli+nbbn0WVKS0ppee7ry8BDdL6uo63N7Sml\nupRS3bhx43qjz5K0qwqedbn95p2kYjLrJA0YhSxy5wMHRsSUiBhEFnjbrKYXEe8ERgGP5W0bFRE1\nuedjgbnAc12PlaR+wKyTVA7MOkkDRsGmK6eUmiPiSuDnQCVwR0rp2Yi4CViQUmoLxvOBe1NK+VNe\nDgb+PSJayQrxW/JX75Ok/sKsk1QOzDpJA0l0zqCBq66uLi1YsKDY3ZDUz0TEwpRSXbH70ZvMO0ld\nmXWSykFPs66Q05UlSZIkSepTFrmSJEmSpJJhkStJkiRJKhkWuZIkSZKkkmGRK0mSJEkqGRa5kiRJ\nkqSSYZErSZIkSSoZFrmSJEmSpJJhkStJkiRJKhkWuZIkSZKkkmGRK0mSJEkqGRa5kiRJkqSSYZEr\nSZIkSSoZFrmSJEmSpJJhkStJkiRJKhkWuZIkSZKkkmGRK0mSJEkqGRa5kiRJkqSSYZErSZIkSSoZ\nFrmSJEmSpJJhkStJkiRJKhkWuZIkSZKkkmGRK0mSJEkqGRa5kiRJkqSSYZErSZIkSSoZFrmSJEmS\npJJhkStJkiRJKhkWuZIkSZKkkmGRK0mSJEkqGRa5kiRJkqSSYZErSZIkSSoZFrmSJEmSpJJR0CI3\nIk6OiBciYlFEXNfN/n+OiCdzjxcjYm3evo9GxEu5x0cL2U9J2hNmnaRyYNZJGiiqCnXiiKgEvgqc\nBNQD8yPi/pTSc21tUkpX57W/Cpidez4auAGoAxKwMHfsW4XqryTtDrNOUjkw6yQNJIUcyT0CWJRS\nejml1AjcC5yxg/bnA9/JPX8f8IuU0ppcAP4COLmAfZWk3WXWSSoHZp2kAaOQRe4BwNK81/W5bduI\niEnAFODXu3JsRFwWEQsiYsHKlSt7pdOStIsKnnW5Y807ScVk1kkaMApZ5EY329J22p4HfC+l1LIr\nx6aUbk8p1aWU6saNG7eb3ZSkPVLwrAPzTlLRmXWSBoxCFrn1wIS81+OB5dtpex4dU1p29VhJKiaz\nTlI5MOskDRiFLHLnAwdGxJSIGEQWePd3bRQR7wRGAY/lbf45MC8iRkXEKGBebpsk9TdmnaRyYNZJ\nGjAKtrpySqk5Iq4kC7FK4I6U0rMRcROwIKXUFoznA/emlFLesWsi4mayQAW4KaW0plB9laTdZdZJ\nKgdmnaSBJPIyaECrq6tLCxYsKHY3JPUzEbEwpVRX7H70JvNOUldmnaRy0NOsK+R0ZUmSJEmS+pRF\nriRJkiSpZFjkSpIkSZJKhkWuJEmSJKlkWORKkiRJkkqGRa4kSZIkqWRY5EqSJEmSSoZFriRJkiSp\nZFjkSpIkSZJKhkWuJEmSJKlkWORKkiRJkkqGRa4kSZIkqWRY5EqSJEmSSoZFriRJkiSpZFjkSpIk\nSZJKhkWuJEmSJKlkWORKkiRJkkqGRa4kSZIkqWRY5EqSJEmSSoZFriRJkiSpZFjkSpIkSZJKhkWu\nJEmSJKlkWORKkiRJkkqGRa4kSZIkqWRY5EqSJEmSSoZFriRJkiSpZFjkSpIkSZJKhkWuJEmSJKlk\nWORKkiRJkkqGRa4kSZIkqWRY5EqSJEmSSoZFriRJkiSpZBS0yI2IkyPihYhYFBHXbafNuRHxXEQ8\nGxH35G1viYgnc4/7C9lPSdoTZp2kcmDWSRooqgp14oioBL4KnATUA/Mj4v6U0nN5bQ4ErgfmppTe\nioi9807RkFKaVaj+SVJvMOsklQOzTtJAUsiR3COARSmll1NKjcC9wBld2nwM+GpK6S2AlNKbBeyP\nJBWCWSepHJh1kgaMQha5BwBL817X57blewf/r737C7XsPMsA/jwkpN5JNKiYVEllIobcFKcF2wsT\n0Dh6YXshNcGLFktChQreCE0RhEJAL4QSCCQR41xpkILpCJVQWoK1WMhEBJ2U0HQUOgRpbKvgRekf\nPy9mR47TM5Ozzux99j7f/v3gMOxvf2vtd9bLeuA9e59zknvafrHtl9qeO/DcD7W9uFp//2Ev0PbR\n1Z6Lb7zxxnqrBziajWddIu+ArZN1wKmxsY8rJ+kha+OQ1z+T5P4kdyX5Qtv7xhj/meSnxhivt31H\nks+3/ecxxlf/38nGeCbJM0ly9uzZa88NcBI2nnWJvAO2TtYBp8Ym38m9kuTtBx7fleT1Q/Z8eozx\n3THGvyZ5NVfDMWOM11f/Xk7yYpJ3brBWgOOSdcA+kHXAqbHJIfelJGfa3t32tiQPJbn2t+k9n+SB\nJGl7R65+zOVy29vbvu3A+nuTvBKA3SPrgH0g64BTY2MfVx5jfK/tR5O8kOSWJM+OMS61/USSi2OM\nC6vnHmz7SpLvJ/n9MUfOIXkAAAeGSURBVMY32r4nydNt/ydXB/E/Ovjb+wB2hawD9oGsA06TjjHH\njzucPXt2XLx4cdtlADum7ctjjLPbrmOd5B1wLVkH7IOjZt0mP64MAAAAJ8qQCwAAwDQMuQAAAEzD\nkAsAAMA0DLkAAABMw5ALAADANAy5AAAATMOQCwAAwDQMuQAAAEzDkAsAAMA0DLkAAABMw5ALAADA\nNAy5AAAATMOQCwAAwDQMuQAAAEzDkAsAAMA0DLkAAABMw5ALAADANAy5AAAATMOQCwAAwDQMuQAA\nAEzDkAsAAMA0DLkAAABMw5ALAADANAy5AAAATMOQCwAAwDQMuQAAAEzDkAsAAMA0DLkAAABMw5AL\nAADANAy5AAAATGOjQ27bc21fbfta249dZ88H2r7S9lLbvziw/sG2X1l9fXCTdQLcDFkH7ANZB5wW\nt27qxG1vSfJkkl9OciXJS20vjDFeObDnTJLHkrx3jPGttj+2Wv+RJH+Y5GySkeTl1bHf2lS9AMch\n64B9IOuA02ST7+S+O8lrY4zLY4zvJHkuyfuu2fNIkiffDLkxxtdX67+S5LNjjG+unvtsknMbrBXg\nuGQdsA9kHXBqbHLIvTPJ1w48vrJaO+ieJPe0/WLbL7U9t+BYgF0g64B9IOuAU2NjH1dO0kPWxiGv\nfybJ/UnuSvKFtvcd8di0fTTJo6uH/93235P81yHH/vAh63ck+Y/rFb8Fh9W4zXMuPfYo+99qz42e\nv95z11vX3/Ude9S9J9Xfpb396QV7j2PjWZf8QN59u+2lQ7bJus0fK+tu7DT3V9bd2K5nXeJ+WOdx\nsu7Gdqm3S4/dj6wbY2zkK8kvJHnhwOPHkjx2zZ6nknzowOPPJXlXkoeTPH1g/ekkDx/hNZ856nqS\ni5v6vx/zeh1a+7bOufTYo+x/qz03en5Jb/V3vccede9J9XcHeyvrll2vU3svHHW/rNudc8q6tfZh\np7NuR6/ZztwPsm43+rCpc8q6H/za5MeVX0pypu3dbW9L8lCSC9fseT7JA0nS9o5c/ZjL5SQvJHmw\n7e1tb0/y4GrtrfzNwvVdsokab+acS489yv632nOj509zb5PT3d+j7t3X/sq6ZU7zvXDU/ft6LySn\nu7+y7sZk3XK7dD/IuvXapd4uPXYvsq6rCXozJ29/Lcknk9yS5NkxxuNtP5GrE/uFtk3yJ7n6ywe+\nn+TxMcZzq2N/O8nHV6d6fIzx52uu7eIY4+w6z8nu0N957WJvZR3bor/z2sXe7nLWrV5j564Z66G3\n89pUbzc65O6yto+OMZ7Zdh1shv7OS2+Xcb3mpr/z0tvlXLN56e28NtXbvR1yAQAAmM8mfyYXAAAA\nTpQhFwAAgGkYcgEAAJiGIXel7Tva/lnbT227Ftar7fvb/mnbT7d9cNv1sF5tf67tU20/1fZ3tl3P\nrpN1c5N385J1y8i6ucm6ea0r66Yects+2/brbf/lmvVzbV9t+1rbjyXJGOPyGOPD26mUpRb29vkx\nxiNJPpTkN7dQLgst7O+XxxgfSfKBJHv55wVk3dzk3bxk3TKybm6ybl7byLqph9wk53P1b7X9n7a3\nJHkyya8muTfJw23vPfnSuEnns7y3f7B6nt13Pgv62/bXk/x9ks+dbJk743xk3czOR97N6nxk3RLn\nI+tmdj6yblbnc8JZN/WQO8b4uyTfvGb53UleW32H7ztJnkvyvhMvjpuypLe96o+T/O0Y4x9PulaW\nW3rvjjEujDHek+S3TrbS3SDr5ibv5iXrlpF1c5N189pG1k095F7HnUm+duDxlSR3tv3Rtk8leWfb\nx7ZTGjfp0N4m+d0kv5TkN9p+ZBuFsRbXu3fvb/tE26eTfGY7pe0kWTc3eTcvWbeMrJubrJvXRrPu\n1put7hTqIWtjjPGNJG6S0+16vX0iyRMnXQxrd73+vpjkxZMt5VSQdXOTd/OSdcvIurnJunltNOv2\n8Z3cK0nefuDxXUle31ItrJfezk1/l3G95qa/89LbZVyvuenvvDba230ccl9Kcqbt3W1vS/JQkgtb\nron10Nu56e8yrtfc9HdeeruM6zU3/Z3XRns79ZDb9i+T/EOSn217pe2HxxjfS/LRJC8k+XKSvxpj\nXNpmnSynt3PT32Vcr7np77z0dhnXa276O69t9LZjjHWdCwAAALZq6ndyAQAA2C+GXAAAAKZhyAUA\nAGAahlwAAACmYcgFAABgGoZcAAAApmHIZSptf6Ltc22/2vaVtp9pe8+26wJYJ1kH7ANZx3EZcplG\n2yb56yQvjjF+Zoxxb5KPJ/nx7VYGsD6yDtgHso6bceu2C4A1eiDJd8cYT725MMb4py3WA7AJsg7Y\nB7KOY/NOLjO5L8nL2y4CYMNkHbAPZB3HZsgFAABgGoZcZnIpyc9vuwiADZN1wD6QdRybIZeZfD7J\n29o+8uZC23e1/cUt1gSwbrIO2AeyjmPrGGPbNcDatP3JJJ/M1e/8fTvJvyX5vTHGV7ZZF8A6yTpg\nH8g6jsuQCwAAwDR8XBkAAIBpGHIBAACYhiEXAACAaRhyAQAAmIYhFwAAgGkYcgEAAJiGIRcAAIBp\nGHIBAACYxv8CCwJjmroHWAYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14c86a62908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_01 = cv_results[cv_results['param_gamma']==0.001]\n",
    "\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_001 = cv_results[cv_results['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_0001 = cv_results[cv_results['param_gamma']==0.00001]\n",
    "\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.00001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots above show some useful insights:\n",
    "- Non-linear models (high gamma) perform *much better* than the linear ones\n",
    "- At any value of gamma, a high value of C leads to better performance\n",
    "- None of the models tend to overfit (even the complex ones), since the training and test accuracies closely follow each other\n",
    "\n",
    "This suggests that the problem and the data is **inherently non-linear** in nature, and a complex model will outperform simple, linear models in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now choose the best hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test score is 0.9394047619047619 corresponding to hyperparameters {'C': 10, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "best_score = model_cv.best_score_\n",
    "best_hyperparams = model_cv.best_params_\n",
    "\n",
    "print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The accuracy achieved using a non-linear kernel (~0.93) is mush higher than that of a linear one (~0.91). We can conclude that the problem is highly non-linear in nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best C=10\n",
    "### Best Gama=.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we have modeled with only 20% data ,we will have much higher accuracy with the completed data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
